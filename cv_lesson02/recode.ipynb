{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gaussian Kernel\n",
    "高斯滤波是一种线性滤波，图像上的每一个像素点的值，都由其本身和邻域内其他像素点的值经过加权平均后得到。由高斯核扫描图像中每一个像素点，将邻域内各个像素值与对应位置的权值相称并求和。从数学的角度来看，高斯滤波的过程是图像与高斯正态分布做卷积操作。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esc():\n",
    "    key = cv2.waitKey()\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(\"/home/ubuntu/Downloads/Learn_CV/cv_lesson02/img/scarlett_4.jpeg\")\n",
    "# img = cv2.imread(\"/home/ubuntu/Downloads/Learn_CV/cv_lesson02/img/000001.jpg\")\n",
    "img = cv2.imread(\"/home/ubuntu/Downloads/Learn_CV/cv_lesson02/img/scarlett_3.jpeg\")\n",
    "cv2.imshow('scarlett', img)\n",
    "esc()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "cv2.**GaussianBlur**(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]]) → dst  \n",
    "**Parameters:**\t \n",
    "  - **src:** - input image; the image can have any number of channels, which are processed independently, but the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.  \n",
    "\n",
    "  - **dst:** - output image of the same size and type as src. \n",
    "\n",
    "  - **ksize:** - Gaussian kernel size. ksize.width and ksize.height can differ but they both must be **positive and odd**. Or, they can be zero’s and then they are computed from sigma* . \n",
    "\n",
    "  - **sigmaX:** - Gaussian kernel standard deviation in X direction.  \n",
    "\n",
    "  - **sigmaY:** - Gaussian kernel standard deviation in Y direction; if sigmaY is zero, it is set to be equal to sigmaX, if both sigmas are zeros, they are computed from ksize.width and ksize.height , respectively (see getGaussianKernel() for details); to fully control the result regardless of possible future modifications of all this semantics, it is recommended to specify all of ksize, sigmaX, and sigmaY.  \n",
    "\n",
    "  - **borderType:** - pixel extrapolation method (see borderInterpolate() for details).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高斯分布的方差（variance，第三个参数）控制图像的模糊程度，越大越模糊\n",
    "g_img = cv2.GaussianBlur(img, (7, 7), 1)\n",
    "cv2.imshow('gaussian_blur_scarlett', g_img)\n",
    "cv2.imshow('scarlett', img)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "cv2.**getGaussianKernel**(ksize, sigma[, ktype]) → retval\n",
    "**Parameters:**\t\n",
    "- **ksize** – Aperture size. It should be odd ( \\texttt{ksize} \\mod 2 = 1 ) and positive.\n",
    "- **sigma** – Gaussian standard deviation. If it is non-positive, it is computed from ksize as sigma = 0.3*((ksize-1)*0.5 - 1) + 0.8 .\n",
    "- **ktype** – Type of filter coefficients. It can be CV_32f or CV_64F .  \n",
    "The function computes and returns the $kesize * 1$ matrix of Gaussian filter coefficients:\n",
    "$$G = \\alpha * e^-\\frac{(i-(ksize-1)/2)^2}{(2×sigma^2)}$$\n",
    "where i=0..$kesize-1$ and $\\alpha$ is the scale factor chosen so that $\\sum_i G_i=1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12895603]\n",
      " [ 0.14251846]\n",
      " [ 0.15133131]\n",
      " [ 0.1543884 ]\n",
      " [ 0.15133131]\n",
      " [ 0.14251846]\n",
      " [ 0.12895603]]\n"
     ]
    }
   ],
   "source": [
    "kernel = cv2.getGaussianKernel(7, 5)\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**sepFilter2D**\n",
    "**ddepth:** Destination image depth. The following combination of src.depth() and ddepth are supported:\n",
    "- src.depth() = CV_8U, ddepth = -1/CV_16S/CV_32F/CV_64F\n",
    "- src.depth() = CV_16U/CV_16S, ddepth = -1/CV_32F/CV_64F\n",
    "- src.depth() = CV_32F, ddepth = -1/CV_32F/CV_64F\n",
    "- src.depth() = CV_64F, ddepth = -1/CV_64F\n",
    "\n",
    "The function applies a separable linear filter to the image. That is, first, every row of src is filtered with the 1D kernel kernelX . Then, every column of the result is filtered with the 1D kernel kernelY . The final result shifted by delta is stored in dst ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二维高斯分离特性：\n",
    "$$G(x,y) = \\frac{1}{2\\pi\\sigma^2}e^-\\frac{x^2+y^2}{2\\sigma^2} = G(x)*G(y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比一维、二维高斯核运行效果\n",
    "# 二维时间复杂度：m*n*ksize*ksize\n",
    "# 一维时间复杂度：m*n*ksize*2\n",
    "# 一维更快\n",
    "g1_img = cv2.GaussianBlur(img, (7, 7), 6)\n",
    "g2_img = cv2.sepFilter2D(img, -1, kernel, kernel)\n",
    "cv2.imshow('scarlett_1', g1_img)\n",
    "cv2.imshow('scarlett_2', g2_img)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Other Applications\n",
    "### 2nd derivative: laplacian(双边缘效果)\n",
    "一阶导： $f(x+) - f(x)$  \n",
    "二阶导： $f(x+2)- 2f(x+1) + f(x)$\n",
    "一阶导粗边；二阶导精细结构，双边效果\n",
    "- 图像： 5  5  4  3  2  1  0  0  0  6  0 0 0\n",
    "- 一阶： 0 -1 -1 -1 -1 -1  0  0  6 -6  0 0 0\n",
    "- 二阶：-1  0  0  0  0  0  1  0  6 -12 6 0 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_lap = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]], np.float32)\n",
    "lap_img = cv2.filter2D(img, -1, kernel = kernel_lap)\n",
    "cv2.imshow('lap_scarlett', lap_img)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 应用： 图像锐化 = edge+ori\n",
    ">app: sharpen\n",
    "图像+edge=更锐利地图像，因为突出边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharp = np.array([[0, 1, 0], [1, -3, 1], [0, 1, 0]], np.float32)\n",
    "sha_img = cv2.filter2D(img, -1, kernel=kernel_sharp)\n",
    "cv2.imshow('lap_scarlett', lap_img)\n",
    "cv2.imshow('sha_scarlett', sha_img)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 这样不对，因为，周围有4个1，中间是-3，虽然有边缘效果，但是周围得1会使得原kernel有滤波效果，使图像模糊；\n",
    "- 解决：所以取kernel_lap得相反数，再加上原图像，这样突出了中心像素，效果类似于小方差的高斯，所以可以既有边缘效果，又保留图像清晰度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharp2 = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], np.float32) \n",
    "sha_img2 = cv2.filter2D(img, -1, kernel=kernel_sharp2)\n",
    "kernel_sharp3 = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32) \n",
    "sha_img3 = cv2.filter2D(img, -1, kernel=kernel_sharp3)\n",
    "cv2.imshow('sha_scarlett2', sha_img2)\n",
    "cv2.imshow('lap_scarlett', lap_img)\n",
    "cv2.imshow('sha_scarlett', sha_img)\n",
    "cv2.imshow('sha_scarlett3', sha_img3)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "更“凶猛”的边缘效果\n",
    "不仅考虑x-y方向上的梯度，同时考虑了对角线方向上的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharp4 = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], np.float32)\n",
    "sha_img4 = cv2.filter2D(img, -1, kernel=kernel_sharp4)\n",
    "cv2.imshow('sha_scarlett2', sha_img4)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection\n",
    "#### x axis\n",
    "x方向梯度，检测y方向的边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgex = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], np.float32)\n",
    "sharp_img = cv2.filter2D(img, -1, kernel=edgex)\n",
    "cv2.imshow('edgex_scarlett', sharp_img)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y axis\n",
    "y方向梯度，检测x方向的边 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgey = np.array([[-1, 0, -1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n",
    "sharpy_img = cv2.filter2D(img, -1, kernel=edgey)\n",
    "cv2.imshow('edgex_scarlett', sharp_img)\n",
    "cv2.imshow('edgey_scarlett', sharpy_img)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 角点\n",
    "cv.**CornerHarris**(image, harris_dst, blockSize, aperture_size=3, k=0.04) → None  \n",
    "- src – Input single-channel 8-bit or floating-point image.\n",
    "- dst – Image to store the Harris detector responses. It has the type CV_32FC1 and the same size as src .\n",
    "- **blockSize** – Neighborhood size (see the details on cornerEigenValsAndVecs() ).\n",
    "- **ksize** – Aperture parameter for the Sobel() operator.\n",
    "- **k** – Harris detector free parameter. See the formula below.\n",
    "- borderType – Pixel extrapolation method. See borderInterpolate() ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/home/ubuntu/Downloads/Learn_CV/cv_lesson02/img/building.jpeg\")\n",
    "img = cv2.resize(img, (600, 500))\n",
    "img_gray = np.float32(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "img_harris = cv2.cornerHarris(img_gray, 2, 3, 0.05)\n",
    "cv2.imshow('img_harris', img_harris)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 看不清\n",
    "没法看原因：1. float类型； 2. img_harris本质上是每个pixel对于Harris函数的响应值\n",
    "没有看的价值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.05 * np.max(img_harris)\n",
    "img[img_harris > thres] = [0, 0, 255]\n",
    "cv2.imshow('building_harris', img)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为了看清\n",
    "膨胀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_harris = cv2.dilate(img_harris, None)\n",
    "thres = 0.05 * np.max(img_harris)\n",
    "img[img_harris > thres] = [0, 0, 255]\n",
    "cv2.imshow('building_harris', img)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT\n",
    "cv2.xfeatures2d.SIFT_create()报错解决：[click](https://stackoverflow.com/questions/52305578/sift-cv2-xfeatures2d-sift-create-not-working-even-though-have-contrib-instal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612, 570, 3)\n",
      "(4.606494426727295, 534.2283935546875)\n",
      "2.0018608570098877\n",
      "0.555877685546875\n",
      "0.024253377690911293\n",
      "7864831\n",
      "-1\n",
      "<class 'cv2.KeyPoint'>\n",
      "(680, 128)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"/home/ubuntu/Downloads/Learn_CV/cv_lesson02/img/scarlett_4.jpeg\")\n",
    "print(img.shape)\n",
    "# create sift class\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# detect SIFT\n",
    "kp = sift.detect(img, None) # None for mask\n",
    "# compute SIFT descritor\n",
    "kp, des = sift.compute(img, kp)\n",
    "print(kp[0].pt)\n",
    "print(kp[0].size)\n",
    "print(kp[0].angle)\n",
    "print(kp[0].response)\n",
    "print(kp[0].octave)\n",
    "print(kp[0].class_id)\n",
    "print(type(kp[0]))\n",
    "print(des.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sift = cv2.drawKeypoints(img, kp, outImage=np.array([]), \n",
    "                             flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow('scarlett_sift', img_sift)\n",
    "esc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
